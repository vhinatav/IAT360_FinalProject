# TOXIC COMMENT MODEL

Our project focuses on training and fine-tuning an NLP model that detects toxic comments, such as hate speech, harassment, or abusive language, in online communications by fine-tuning BERT (bert-based-uncased), a bidirectional transformer-based pre-trained language model introduced by Google in 2018 (reference: https://huggingface.co/google-bert/bert-base-uncased).

### File Descriptions
- ToxicCommentModel.ipynb
- Training_Results.zip: Contain png files of training results
- Evaluation_Results.zip: Contain png files of evaluation results
