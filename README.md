# TOXIC COMMENT MODEL

Our project focuses on training and fine-tuning an NLP model that detects toxic comments, such as hate speech, harassment, or abusive language, in online communications by fine-tuning BERT (bert-based-uncased), a bidirectional transformer-based pre-trained language model introduced by Google in 2018 (reference: https://huggingface.co/google-bert/bert-base-uncased).

### File Descriptions
- ToxicCommentModel.ipynb
- DataConvert.ipynb
- Dataset.zip
  - Original: https://huggingface.co/datasets/SetFit/toxic_conversations
  - Modified to 30000 rows: https://huggingface.co/datasets/vhinatav/360toxicdata30000
- Training_Results.zip: Contain png files of training results
- Evaluation_Results.zip: Contain png files of evaluation results
